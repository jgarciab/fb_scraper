{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FB scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: selenium in /home/javiergb/Programs/anaconda3/lib/python3.5/site-packages (3.141.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3 in /home/javiergb/Programs/anaconda3/lib/python3.5/site-packages (from selenium) (1.23)\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import selenium               # Loads dynamic (javascript) pages\n",
    "import selenium.webdriver               # Loads dynamic (javascript) pages\n",
    "import time\n",
    "import os\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘images’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import selenium.common.exceptions\n",
    "import selenium.webdriver\n",
    "import selenium.webdriver.common.desired_capabilities\n",
    "import selenium.webdriver.support.ui\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "\n",
    "#Define a function to wait for an element to load\n",
    "def _wait_for_element(wait):\n",
    "    try:\n",
    "        polling_f = expected_conditions.presence_of_element_located((selenium.webdriver.common.by.By.TAG_NAME, \"img\"))\n",
    "        elem = wait.until(polling_f)\n",
    "    except:\n",
    "        raise selenium.common.exceptions.TimeoutException(msg='Wait timeout.')\n",
    "    return elem\n",
    "\n",
    "\n",
    "#define short and long timeouts\n",
    "wait_timeouts=(30, 180)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_save_figs(driver,group,SCROLL_PAUSE_TIME = 5):\n",
    "    #maker folder\n",
    "    !mkdir -p images/$group\n",
    "    \n",
    "    #go to the site (make sure it's a public group)\n",
    "    driver.get(\"https://www.facebook.com/groups/{}/members/\".format(group))\n",
    "\n",
    "    \n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    i = 0 #the first image is your profile photo\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        \n",
    "        # Process new images (wait until it is not stale, sometimes it fails)\n",
    "        images = _wait_for_element(long_wait)\n",
    "        images = driver.find_elements_by_tag_name('img')\n",
    "        \n",
    "        new_images = images[i:]\n",
    "        down_images = os.listdir(\"./images/{}\".format(group))\n",
    "        for img in new_images:\n",
    "            \n",
    "            try:\n",
    "                img_src = img.get_attribute(\"src\")\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "            if not \"320x320\" in img_src: #that's the resolution of the photos of the members\n",
    "                continue\n",
    "            i += 1\n",
    "    \n",
    "            if i%100 == 0:\n",
    "                print(\"{}\".format(i), end=\" : \")\n",
    "                \n",
    "            if i == 3000:\n",
    "                return None\n",
    "            fname = img_src[:img_src.find(\"jpg?\")+3]\n",
    "            fname = fname[fname.rfind(\"/\")+1:]\n",
    "            if fname not in down_images:\n",
    "                urlretrieve(img_src,\"./images/{}/{}\".format(group,fname))\n",
    "        \n",
    "\n",
    "\n",
    "#         # Calculate new scroll height and compare with last scroll height\n",
    "#         new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#         if new_height == last_height:\n",
    "#             break\n",
    "#         last_height = new_height\n",
    "        \n",
    "#     time.sleep(SCROLL_PAUSE_TIME*10)\n",
    "#     #Get all images that were missing\n",
    "#     images = driver.find_elements_by_tag_name('img')\n",
    "\n",
    "#     down_images = os.listdir(\"./images/{}\".format(group))\n",
    "#     new_images = images[i:]\n",
    "#     for img in new_images:\n",
    "#         try:\n",
    "#             img_src = img.get_attribute(\"src\")\n",
    "#         except:\n",
    "#             break \n",
    "\n",
    "#         if not \"320x320\" in img_src: #that's the resolution of the photos of the members\n",
    "#             continue\n",
    "#         i += 1\n",
    "\n",
    "#         fname = img_src[:img_src.find(\"jpg?\")+3]\n",
    "#         fname = fname[fname.rfind(\"/\")+1:]\n",
    "#         if fname not in down_images:\n",
    "#             urlretrieve(img_src,\"./images/{}/{}\".format(group,fname))\n",
    "\n",
    "#     !git add .  &> /dev/null\n",
    "#     !git commit -m \"update\"  &> /dev/null\n",
    "#     !git push origin master  &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "# Open the driver (change the executable path to geckodriver_mac.exe or geckodriver.exe)\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    driver = selenium.webdriver.Chrome(executable_path=\"./chromedriver\")\n",
    "elif platform == \"darwin\":\n",
    "    driver = selenium.webdriver.Chrome(executable_path=\"./chromedriver_mac\")\n",
    "elif platform == \"win32\":\n",
    "    \"download the chromedriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now log-in facebook \n",
    "driver.get(\"https://www.facebook.com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Avoid stale elements\n",
    "#define short and long waits (for the times you have to wait for the page to load)\n",
    "short_wait = selenium.webdriver.support.ui.WebDriverWait(driver, wait_timeouts[0], poll_frequency=0.05)\n",
    "long_wait = selenium.webdriver.support.ui.WebDriverWait(driver, wait_timeouts[1], poll_frequency=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log in facebook! And if there are notifications (allow Chrome to xxx) block it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = [\"1472997079606848\",\"243857799756496\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 : 200 : 300 : 400 : 500 : 600 : 700 : 800 : 900 : 1000 : 1100 : 1200 : 100 : 200 : 300 : 400 : 500 : 600 : 700 : 800 : 900 : 1000 : 1100 : 1200 : 1300 : 1400 : 1500 : 1600 : 1700 : 1800 : "
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    load_save_figs(driver,group,SCROLL_PAUSE_TIME = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch and 'origin/master' have diverged,\n",
      "and have 1 and 11 different commits each, respectively.\n",
      "  (use \"git pull\" to merge the remote branch into yours)\n",
      "\n",
      "nothing to commit, working tree clean\n",
      "To https://github.com/jgarciab/fb_scraper.git\n",
      " ! [rejected]          master -> master (fetch first)\n",
      "error: failed to push some refs to 'https://github.com/jgarciab/fb_scraper.git'\n",
      "hint: Updates were rejected because the remote contains work that you do\n",
      "hint: not have locally. This is usually caused by another repository pushing\n",
      "hint: to the same ref. You may want to first integrate the remote changes\n",
      "hint: (e.g., 'git pull ...') before pushing again.\n",
      "hint: See the 'Note about fast-forwards' in 'git push --help' for details.\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"update\"\n",
    "!git push origin master "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
